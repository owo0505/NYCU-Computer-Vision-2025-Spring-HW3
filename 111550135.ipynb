{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q 'git+https://github.com/facebookresearch/detectron2.git'\n",
    "!pip install imagecodecs\n",
    "!pip install iterative-stratification\n",
    "!pip install ensemble-boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from skimage import io as skio\n",
    "import numpy as np\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "\n",
    "ROOT = Path('/path/to/hw3-data-release')\n",
    "TRAIN_DIR = ROOT / 'train'\n",
    "TEST_DIR = ROOT / 'test_release'\n",
    "VAL_RATIO = 0.15\n",
    "\n",
    "img_dirs = sorted([p for p in TRAIN_DIR.iterdir() if p.is_dir()])\n",
    "Y = []\n",
    "for d in img_dirs:\n",
    "    flags = [0, 0, 0, 0]\n",
    "    for m in d.glob('class*.tif'):\n",
    "        cls = int(m.stem.replace('class', '')) - 1\n",
    "        if np.any(skio.imread(m)):\n",
    "            flags[cls] = 1\n",
    "    Y.append(flags)\n",
    "Y = np.array(Y)\n",
    "\n",
    "msss = MultilabelStratifiedShuffleSplit(\n",
    "    n_splits=1, test_size=VAL_RATIO, random_state=2025)\n",
    "train_idx, val_idx = next(msss.split(np.zeros(len(Y)), Y))\n",
    "\n",
    "train_names = {img_dirs[i].name for i in train_idx}\n",
    "val_names = {img_dirs[i].name for i in val_idx}\n",
    "\n",
    "print(f\"Train folders: {len(train_names)} | Val folders: {len(val_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "from pycocotools import mask as mask_utils\n",
    "\n",
    "def make_cells_dicts(img_dir, allowed_names, is_test=False):\n",
    "    records = []\n",
    "    for idx, d in enumerate(sorted(img_dir.iterdir())):\n",
    "        if (not d.is_dir()) or (d.name not in allowed_names):\n",
    "            continue\n",
    "        img_path = d / 'image.tif'\n",
    "        h, w = skio.imread(img_path).shape[: 2]\n",
    "        rec = {\n",
    "            \"file_name\": str(img_path),\n",
    "            \"image_id\": idx,\n",
    "            \"height\": h,\n",
    "            \"width\": w,\n",
    "            \"annotations\": []\n",
    "        }\n",
    "        if not is_test:\n",
    "            annos = []\n",
    "            for mask_path in d.glob('class*.tif'):\n",
    "                cls = int(mask_path.stem.replace('class', '')) - 1\n",
    "                arr = skio.imread(mask_path)\n",
    "                for inst in np.unique(arr)[1:]:\n",
    "                    m = (arr == inst).astype('uint8')\n",
    "                    rle = mask_utils.encode(np.asfortranarray(m))\n",
    "                    rle[\"counts\"] = rle[\"counts\"].decode('utf-8')\n",
    "                    ys, xs = np.where(m)\n",
    "                    xmin, ymin = xs.min(), ys.min()\n",
    "                    annos.append({\n",
    "                        \"bbox\": [int(xmin), int(ymin),\n",
    "                                 int(xs.max() - xmin + 1),\n",
    "                                 int(ys.max() - ymin + 1)],\n",
    "                        \"bbox_mode\": BoxMode.XYWH_ABS,\n",
    "                        \"category_id\": cls,\n",
    "                        \"segmentation\": rle,\n",
    "                        \"iscrowd\": 0\n",
    "                    })\n",
    "            rec[\"annotations\"] = annos\n",
    "        records.append(rec)\n",
    "    return records\n",
    "\n",
    "DatasetCatalog.register(\n",
    "    \"cells_train\",\n",
    "    lambda: make_cells_dicts(TRAIN_DIR, train_names, is_test=False)\n",
    ")\n",
    "DatasetCatalog.register(\n",
    "    \"cells_val\",\n",
    "    lambda: make_cells_dicts(TRAIN_DIR, val_names, is_test=False)\n",
    ")\n",
    "DatasetCatalog.register(\n",
    "    \"cells_test\",\n",
    "    lambda: make_cells_dicts(ROOT / 'test_release', set(), is_test=True)\n",
    ")\n",
    "MetadataCatalog.get(\"cells_train\").set(thing_classes=['c1', 'c2', 'c3', 'c4'])\n",
    "MetadataCatalog.get(\"cells_val\").set(thing_classes=['c1', 'c2', 'c3', 'c4'])\n",
    "MetadataCatalog.get(\"cells_test\").set(thing_classes=['c1', 'c2', 'c3', 'c4'])\n",
    "\n",
    "print(\"✅ cells_train / cells_val / cells_test 都註冊完了！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\".*torch.cuda.amp.autocast.*\",\n",
    "    category=FutureWarning\n",
    ")\n",
    "\n",
    "setup_logger()\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\n",
    "    \"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "\n",
    "cfg.MODEL.DEVICE = \"cuda\"\n",
    "cfg.SOLVER.AMP.ENABLED = True\n",
    "cfg.SOLVER.CLIP_GRADIENTS.ENABLED = True\n",
    "cfg.SOLVER.CLIP_GRADIENTS.CLIP_TYPE = \"value\"\n",
    "cfg.SOLVER.CLIP_GRADIENTS.CLIP_VALUE = 1.0\n",
    "cfg.DATASETS.TRAIN = (\"cells_train\",)\n",
    "cfg.DATASETS.TEST = (\"cells_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[8], [16], [32], [64], [128]]\n",
    "cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.5, 1.0, 2.0]]\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 15000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 3000\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.BACKBONE.FREEZE_AT = 2\n",
    "cfg.MODEL.ROI_MASK_HEAD.POOLER_RESOLUTION = 28\n",
    "cfg.MODEL.ROI_MASK_HEAD.NUM_CONV = 4\n",
    "cfg.MODEL.ROI_MASK_HEAD.CONV_DIM = 256\n",
    "cfg.INPUT.MIN_SIZE_TRAIN = (800,)\n",
    "cfg.INPUT.MAX_SIZE_TRAIN = 1333\n",
    "cfg.INPUT.RANDOM_FLIP = \"horizontal\"\n",
    "# cfg.INPUT.RANDOM_FLIP = \"vertical\"\n",
    "cfg.DATALOADER.SAMPLER_TRAIN = \"RepeatFactorTrainingSampler\"\n",
    "cfg.DATALOADER.REPEAT_THRESHOLD = 0.05\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 2e-3\n",
    "cfg.SOLVER.WEIGHT_DECAY = 1e-4\n",
    "cfg.SOLVER.MAX_ITER = 6000\n",
    "cfg.SOLVER.WARMUP_ITERS = 500\n",
    "cfg.SOLVER.WARMUP_FACTOR = 1. / 1000\n",
    "cfg.SOLVER.STEPS = (4500, 5500)\n",
    "cfg.SOLVER.GAMMA = 0.1\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 500\n",
    "cfg.TEST.AUG.ENABLED = True\n",
    "cfg.TEST.AUG.MIN_SIZES = (800,)\n",
    "cfg.TEST.AUG.MAX_SIZE = 1333\n",
    "cfg.TEST.AUG.FLIP = True\n",
    "cfg.SEED = 2025\n",
    "cfg.OUTPUT_DIR = \"/path/to/output\"\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\n",
    "    \"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")\n",
    "cfg.TEST.EVAL_PERIOD = 500\n",
    "cfg.INPUT.MASK_FORMAT = \"bitmask\"\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "class CocoTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "\n",
    "trainer = CocoTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_json(\"/path/to/output/metrics.json\", lines=True)\n",
    "\n",
    "total_loss = df.dropna(subset=[\"total_loss\"])\n",
    "plt.plot(total_loss[\"iteration\"],\n",
    "         total_loss[\"total_loss\"],\n",
    "         label=\"total_loss\")\n",
    "\n",
    "loss_mask = df.dropna(subset=[\"loss_mask\"])\n",
    "plt.plot(loss_mask[\"iteration\"],\n",
    "         loss_mask[\"loss_mask\"],\n",
    "         label=\"loss_mask\")\n",
    "\n",
    "segm_AP = df.dropna(subset=[\"segm/AP\"])\n",
    "plt.plot(segm_AP[\"iteration\"],\n",
    "         segm_AP[\"segm/AP\"],\n",
    "         label=\"segm/AP\")\n",
    "\n",
    "segm_AP50 = df.dropna(subset=[\"segm/AP50\"])\n",
    "plt.plot(segm_AP50[\"iteration\"],\n",
    "         segm_AP50[\"segm/AP50\"],\n",
    "         label=\"segm/AP50\")\n",
    "\n",
    "segm_AP_c1 = df.dropna(subset=[\"segm/AP-c1\"])\n",
    "plt.plot(segm_AP_c1[\"iteration\"],\n",
    "         segm_AP_c1[\"segm/AP-c1\"],\n",
    "         label=\"segm/AP-c1\")\n",
    "\n",
    "segm_AP_c2 = df.dropna(subset=[\"segm/AP-c2\"])\n",
    "plt.plot(segm_AP_c2[\"iteration\"],\n",
    "         segm_AP_c2[\"segm/AP-c2\"],\n",
    "         label=\"segm/AP-c2\")\n",
    "\n",
    "segm_AP_c3 = df.dropna(subset=[\"segm/AP-c3\"])\n",
    "plt.plot(segm_AP_c3[\"iteration\"],\n",
    "         segm_AP_c3[\"segm/AP-c3\"],\n",
    "         label=\"segm/AP-c3\")\n",
    "\n",
    "segm_AP_c4 = df.dropna(subset=[\"segm/AP-c4\"])\n",
    "plt.plot(segm_AP_c4[\"iteration\"],\n",
    "         segm_AP_c4[\"segm/AP-c4\"],\n",
    "         label=\"segm/AP-c4\")\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from detectron2.engine import DefaultPredictor\n",
    "\n",
    "# cfg.MODEL.WEIGHTS = \"/path/to/0322_19_model_0002999.pth\"\n",
    "cfg.MODEL.WEIGHTS = \"/path/to/0320_18_model_0002999.pth\"\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.001\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 1000\n",
    "cfg.MODEL.DEVICE = \"cuda\"\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "with open(\"/path/to/test_image_name_to_ids.json\") as f:\n",
    "    name2id = {x[\"file_name\"]: x[\"id\"] for x in json.load(f)}\n",
    "\n",
    "submissions = []\n",
    "for img_file in tqdm(sorted(TEST_DIR.glob(\"*.tif\")), desc=\"Inference\"):\n",
    "    im = cv2.imread(str(img_file))\n",
    "    assert im.dtype == np.uint8, f\"{img_file} not uint8\"\n",
    "\n",
    "    insts = predictor(im)[\"instances\"].to(\"cpu\")\n",
    "    for mask, label, score in zip(insts.pred_masks,\n",
    "                                  insts.pred_classes,\n",
    "                                  insts.scores):\n",
    "        rle = mask_utils.encode(np.asfortranarray(mask.numpy()))\n",
    "        rle[\"counts\"] = rle[\"counts\"].decode(\"utf-8\")\n",
    "        submissions.append({\n",
    "            \"image_id\": name2id[img_file.name],\n",
    "            \"category_id\": int(label) + 1,\n",
    "            \"segmentation\": rle,\n",
    "            \"score\": float(score)\n",
    "        })\n",
    "\n",
    "with open(\"test-results.json\", \"w\") as f:\n",
    "    json.dump(submissions, f)\n",
    "print(\"✅ submission  saved: test-results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.structures import Boxes, pairwise_iou\n",
    "from ensemble_boxes import weighted_boxes_fusion\n",
    "\n",
    "def build_pred(weight_path):\n",
    "    cfg.MODEL.WEIGHTS = weight_path\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.001\n",
    "    cfg.TEST.DETECTIONS_PER_IMAGE = 1000\n",
    "    cfg.MODEL.DEVICE = \"cuda\"\n",
    "    return DefaultPredictor(cfg)\n",
    "\n",
    "def wbf_one_image(outs, H, W, iou_thr=0.55, skip_thr=0.0):\n",
    "    boxes, scores, labels = [], [], []\n",
    "    for inst in outs:\n",
    "        b = inst.pred_boxes.tensor.numpy()\n",
    "        b = b / np.array([W, H, W, H])\n",
    "        s = inst.scores.numpy()\n",
    "        label = inst.pred_classes.numpy()\n",
    "        boxes.append(b)\n",
    "        scores.append(s)\n",
    "        labels.append(label)\n",
    "\n",
    "    b, s, label = weighted_boxes_fusion(\n",
    "        boxes, scores, labels,\n",
    "        iou_thr=iou_thr, skip_box_thr=skip_thr\n",
    "    )\n",
    "    b = b * np.array([W, H, W, H])\n",
    "    return b, s, label\n",
    "\n",
    "pred_a = build_pred(\"/path/to/0320_18_model_0002999.pth\")\n",
    "pred_b = build_pred(\"/path/to/0322_19_model_0002999.pth\")\n",
    "\n",
    "with open(\"/path/to/test_image_name_to_ids.json\") as f:\n",
    "    name2id = {x[\"file_name\"]: x[\"id\"] for x in json.load(f)}\n",
    "\n",
    "submissions = []\n",
    "for img_file in tqdm(sorted(TEST_DIR.glob(\"*.tif\")), desc=\"WBF Inference\"):\n",
    "    im = cv2.imread(str(img_file))\n",
    "    H, W = im.shape[:2]\n",
    "\n",
    "    inst1 = pred_a(im)[\"instances\"].to(\"cpu\")\n",
    "    inst2 = pred_b(im)[\"instances\"].to(\"cpu\")\n",
    "\n",
    "    boxes, scores, labels = wbf_one_image([inst1, inst2], H, W, 0.6, 0.0)\n",
    "\n",
    "    for xyxy, sc, lb in zip(boxes, scores, labels):\n",
    "        all_insts = [inst1, inst2]\n",
    "        best_mask = None\n",
    "        best_iou = -1\n",
    "        for inst in all_insts:\n",
    "            if len(inst) == 0:\n",
    "                continue\n",
    "            ious = pairwise_iou(\n",
    "                Boxes(torch.tensor([xyxy])),\n",
    "                inst.pred_boxes\n",
    "            ).numpy()[0]\n",
    "            idx = ious.argmax()\n",
    "            if ious[idx] > best_iou:\n",
    "                best_iou = ious[idx]\n",
    "                best_mask = inst.pred_masks[idx].numpy()\n",
    "\n",
    "        if best_mask is None:\n",
    "            continue\n",
    "\n",
    "        rle = mask_utils.encode(np.asfortranarray(best_mask.astype(np.uint8)))\n",
    "        rle[\"counts\"] = rle[\"counts\"].decode(\"utf-8\")\n",
    "        submissions.append({\n",
    "            \"image_id\": name2id[img_file.name],\n",
    "            \"category_id\": int(lb) + 1,\n",
    "            \"segmentation\": rle,\n",
    "            \"score\": float(sc),\n",
    "        })\n",
    "\n",
    "with open(\"test-results.json\", \"w\") as f:\n",
    "    json.dump(submissions, f)\n",
    "print(\"✅ WBF submission saved!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7255990,
     "sourceId": 11573335,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7303859,
     "sourceId": 11697614,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
